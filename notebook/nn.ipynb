{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''a simple one_hot_encoder which encode the numbers from 0 to 9 in vector\n",
    "for example: if y = 3  then one hot vector is [0,0,0,1,0,0,0,0,0,0]'''\n",
    "\n",
    "def one_hot_encode(y, num_classes=10):\n",
    "    m = y.shape[0]\n",
    "    one_hot = np.zeros((m, num_classes))\n",
    "    one_hot[np.arange(m), y] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ReLU (Rectified Linear Unit) its a simple to introduce non-linearity means it just convert y = x if x>0 and y = 0 if x < 0 '''\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)   #if Z<0 then return 0 otherwise return Z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def softmax(Z):\n",
    "    max_val = np.max(Z, axis=0, keepdims=True)\n",
    "    Z_stable = Z - max_val\n",
    "    exp_vals = np.exp(Z_stable)\n",
    "    total = np.sum(exp_vals, axis=0, keepdims=True)\n",
    "    return exp_vals / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'here i am trying to explain the softmax fucntion and its use'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"here i am trying to explain the softmax fucntion and its use: \n",
    "\n",
    "Suppose for one sample (a single column in Z2) the output is:\n",
    "\n",
    "Z2 = [2.3,0.5,-1.2,0.0,1.8,-0.7,-0.2,0.3,-1.0,0.9] ---->logits\n",
    "\n",
    "The logit for class 0 is 2.3, for class 1 is 0.5, for class 2 is -1.2, and so on.\n",
    "\n",
    "These numbers indicate how strongly the network \"favors\" each class before normalization\n",
    "\n",
    "after softmax function .....\n",
    "\n",
    "This is how the softmax function transforms the raw logits into a meaningful output probability vector \n",
    "\n",
    "A2 = [0.40766853, 0.06738715, 0.01231052, 0.04087238, 0.24726346,0.02029662, 0.03346347, 0.05517194, 0.01503611, 0.10052982]\n",
    "\n",
    "A2[0]≈0.4076: The network estimates a 40.76% probability for class 0.\n",
    "\n",
    "A2[4]≈0.2473: About 24.73% for class 4.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40766853, 0.06738715, 0.01231052, 0.04087238, 0.24726346,\n",
       "       0.02029662, 0.03346347, 0.05517194, 0.01503611, 0.10052982])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2 = [2.3,0.5,-1.2,0.0,1.8,-0.7,-0.2,0.3,-1.0,0.9]\n",
    "A2 = softmax(Z2)\n",
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(Y_pred, Y_true):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Class: Neural_Network\n",
    "\n",
    "### This class encapsulates the network architecture, forward pass, backward propagation, parameter updates, training, and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input_size = no of input neurons 784 (28*28)\n",
    "\n",
    "output_size = no of class (10)  from 0 to 9\n",
    "\n",
    "hidden_size = number of neurons in the hidden layer\n",
    "\n",
    "learning_rate =  Step size for gradient descent updates\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "input_size = 784      \n",
    "hidden_size = 64      \n",
    "output_size = 10      \n",
    "learning_rate = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    '''np.random.randn(hidden_size, input_size)  because for each hidden neuron we need x weights and here x no of input so fo y neuron we need xy weights\n",
    "\n",
    "    so here using np i create a 2d matrix of x row and y cols \n",
    "\n",
    "    the scalling factor is selected only becuase its perfect for relu and you can change it ..... \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        #from input layer to hidden layer\n",
    "        self.W1 = np.random.randn(hidden_size, input_size) * np.sqrt(2. / input_size)\n",
    "        self.b1 = np.zeros((hidden_size, 1))\n",
    "        \n",
    "        #from hidden layer to ouput layer\n",
    "        self.W2 = np.random.randn(output_size, hidden_size) * np.sqrt(2. / hidden_size)\n",
    "        self.b2 = np.zeros((output_size, 1))\n",
    "\n",
    "    \n",
    "    def forward(self,X):\n",
    "        #simple forward pass  Z1 = W1*X +B1\n",
    "        Z1 = np.dot(self.W1,X)+self.b1\n",
    "        A1 = relu(Z1)\n",
    "\n",
    "\n",
    "        #simple forward pass  Z2 = W1*A1 +B2\n",
    "        Z2 = np.dot(self.W2,A1)+self.b2\n",
    "        \n",
    "        \n",
    "        A2 = softmax(Z2)\n",
    "\n",
    "        #cache: Save intermediate values needed for backpropagation.\n",
    "        cache = (X, Z1, A1, Z2, A2)\n",
    "        \n",
    "        return A2, cache\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
